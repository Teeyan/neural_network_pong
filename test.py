import numpy as np
import scipy.special

A = np.array([
[0.0976270078546,0.430378732745,0.205526752143,0.0897663659938,-0.152690401322,0.291788226133,-0.124825577475,0.783546001564],
[0.927325521002,-0.233116962348,0.583450076165,0.0577898395058,0.136089122188,0.851193276585,-0.857927883604,-0.825741400597],
[-0.959563205119,0.665239691096,0.5563135019,0.740024296494,0.957236684466,0.598317128433,-0.0770412754941,0.561058352573],
[-0.763451148262,0.279842042655,-0.713293425182,0.889337834099,0.0436966435001,-0.170676120019,-0.470888775791,0.548467378868],
[-0.0876993355669,0.136867897737,-0.962420399127,0.235270994152,0.224191445445,0.23386799375,0.887496157029,0.363640598207],
[-0.280984198852,-0.125936092401,0.395262391855,-0.879549056741,0.333533430891,0.341275739236,-0.579234877852,-0.74214740469],
[-0.369143298152,-0.272578458115,0.140393540836,-0.122796973075,0.976747676118,-0.795910378504,-0.58224648781,-0.67738096423],
[0.306216650931,-0.49341679492,-0.0673784542874,-0.511148815997,-0.682060832709,-0.779249717671,0.312659178931,-0.723634097303],
[-0.60683527664,-0.262549658678,0.641986459696,-0.805797448414,0.675889814998,-0.807803184212,0.952918930027,-0.0626975967046],
[0.953522176381,0.20969103949,0.478527158797,-0.921624415491,-0.434386074847,-0.759606877574,-0.407719604956,-0.762544562092]
	])

W = np.array([
[0.317983179394,0.414262994515,0.0641474963488,0.69247211937],
[0.566601454207,0.265389490939,0.523248053467,0.0939405107584],
[0.575946495556,0.929296197576,0.318568952451,0.667410379964],
[0.131797862404,0.716327204119,0.289406092947,0.183191362007],
[0.58651293481,0.0201075461875,0.828940029217,0.00469547619255],
[0.677816536796,0.270007973192,0.735194022123,0.962188545117],
[0.24875314352,0.576157334418,0.592041931272,0.572251905791],
[0.223081632641,0.952749011517,0.447125378618,0.846408672471]
	])

b = np.array([0.699479275318, 0.297436950855, 0.813797819702, 0.396505740847 ])

dZ = np.array([
[0.762206394222,0.162545745272,0.76347072371,0.385063180156],
[0.450508559639,0.0026487638534,0.912167269446,0.287980398459],
[-0.152289902884,0.212786428256,-0.961613603381,-0.396850366651],
[0.320347074985,-0.419844785579,0.236030857998,-0.142462598108],
[-0.729051871555,-0.403435348088,0.139929821403,0.181745522496],
[0.148650497699,0.306401639714,0.304206540003,-0.137163129132],
[0.793093191702,-0.264876259904,-0.128270149469,0.783846710031],
[0.612387978092,0.407777167081,-0.799546225375,0.838965227489],
[0.428482599098,0.997694013136,-0.701103390684,0.736252114736],
[-0.675014130647,0.231119128568,-0.752360034301,0.696016458644] 
	])

Z = np.array([
[1.3565476213,1.45771394424,1.50109965789,1.52996162149],
[1.46507229855,0.154860821512,0.815361956687,1.04652279418],
[2.26219902,1.79451057522,2.93034410997,1.3123696034],
[0.236827022288,0.235670995932,0.818587410666,-0.388271700598],
[0.817747243124,0.497036862725,1.68708708207,0.79114179937],
[0.767800816841,-1.05707251906,0.453867861946,-0.336912607238],
[0.229776388413,-1.06142232183,0.233607024277,-1.48127943772],
[-0.600774727804,-0.868839796371,-0.870867878022,-0.762964836374],
[0.693232976094,0.280523916818,1.11132084879,-0.0493649852366],
[0.234454074768,-0.642654040537,-0.630474086786,-0.384635229845],
])

dA = np.array([
[0.61463791745,0.138201477229,-0.185633405548,-0.86166600909],
[0.394857546289,-0.0929146346439,0.444111198941,0.732764651857],
[0.951043010006,0.711606684785,-0.97657183163,-0.280043871043],
[0.459981124848,-0.656740645477,0.0420732124083,-0.891324023321],
[-0.600006950207,-0.962956411079,0.587395406715,-0.552150623879],
[-0.309296638606,0.856162586931,0.408828803847,-0.936322140937],
[-0.670611687004,0.242956803,0.154457177208,-0.524214357251],
[0.86842799585,0.227931911932,0.0712656060499,0.179819952709],
[0.460244059034,-0.376110009041,-0.203557875568,-0.58031250205],
[-0.627613988239,0.888744779968,0.479101590099,-0.0190823827649]
	])

F = np.array([
[-0.5451707440533535,-0.4912870364592141,-0.8839416793522488],
[-0.13116674888375845,-0.37640823601179485,0.392686977630919],
[-0.2444963214150382,-0.6407926448807304,-0.9506425432173375],
[-0.8655007370735028,0.3587855469971346,-0.09260631088790938],
[0.0731584222174444,0.7933425860806842,0.9806778947934087],
[-0.5662060312030521,0.3261564062002016,-0.4733552465256987],
[-0.9586980010685426,0.5167573076722829,-0.3599656983550643],
[-0.23307221165620406,0.17663422710721144,0.6620969104723808],
[0.25796368718229745,0.7453013108947906,-0.45291593036872846],
[0.5960936678251274,-0.6287281113880956,0.9055833139438891]
	])

y = np.array([0,0,0,1,0,2,2,2,0,0])


def cross_entropy(f, y):
	"""
	Computes the loss function L and the gradients of the loss w.r.t the scores F
	:param f: logits scores for the predictions np array of size (n, 3)
	:param y: target classes for the observations - np array of size (n,)
	:return: loss L and the gradient dlogits
	"""
	n = len(y)
	# Compute the loss L and the gradient dlogits
	loss = 0
	dlogits = np.zeros(shape=f.shape)
	for i in range(0, n):
		# loss computation using logsumexp for stability
		loss = loss + (f[i, int(y[i])] - scipy.special.logsumexp(f[i,:]))
		# gradient dlogits computation
		for j in range(0, len(f[0])):
			inner = 1 if j == y[i] else 0
			inner = inner - (np.exp(f[i, j]) / np.sum(np.exp(f[i,:])))
			dlogits[i, j] = (-1 / n) * inner
	loss = loss * (-1 / n)
	return loss, dlogits

def affine_backwards(diff_z, data, weights):
	"""
	Compute the gradients of the loss L with respect to the forward propogation inputs A  W  b
	:param diff_z: gradient dZ - 2d numpy array of shape n x d'
	:param data: the affine output of the affine forward operation
	:param weights: layer weight matrix np array of shape d x d'
	:return: dA - gradient dA w.r.t. the loss - 2d numpy array of shape n x d
	:return: dW - gradient dW w.r.t the loss - 2d numpy array of shape d x d'
	:return: db - gradient of the bias - numpy array of shape (d' )
	"""
	# Calculate the gradient of the data
	dA = np.dot(diff_z, np.swapaxes(weights, 0, 1))
	# Calculate the gradient of the weights
	dW = np.dot(np.swapaxes(data, 0 , 1), diff_z)
	# Calculate the gradient of the bias
	db = np.sum(diff_z, 0)

	return dA, dW, db


def affine_forward(data, weights, bias):
	"""
	Compute,an,affine,transformation,on,the,data,in,forward,propogation,where,d',is,the,number,of,layer,units
	:param,data:,2D,numpy,array,of,shap,n,x,d
	:param,weights:,layer,weight,matrix,np,array,of,shape,d,x,d'
	:param,bias:,bias,array,b,->,np,array,of,shape,(d',)
	:return:,Z,-,affine,output,of,the,transformation,2d,numpy,array,of,shape,n,x,d'
	"""
	z=np.dot(data, weights)
	return z + bias

def relu_forward(z):
	"""
	Compute,the,elementwise,ReLu,of,Z,where,a,relu,is,simply
		xi,=,{,xi,for,xi,>,0,|,0,otherwise,}
	:param,z:,batch,z,matrix,,2d,numpy,array,of,size,n,x,d'
	:return:,ReLU,output,,2d,array,of,size,n,x,d'
	"""
	relu_z = np.copy(z)
	relu_z[relu_z < 0] = 0
	return relu_z


def relu_backward(diff_a, zeroed):
	"""
	Computes,gradient,of,Z,with,respect,to,loss.,Z,and,the,a,are,the,same,shape
	:param,diff_a:,differential,of,the,data,(zeroed,out)
	:param,zeroed:,zeroed,out,data
	:return:,gradient,of,z,with,respect,to,the,loss,L
	"""
	diff_z = np.copy(diff_a)
	for i in range(0,len(zeroed)):
		for j in range(0,len(zeroed[0])):
				if zeroed[i,j] < 0:
					diff_z[i,j] = 0
	return diff_z


def main():
	# Test cross entropy
	aff_for = affine_forward(A, W, b)
	np.savetxt("affine_forward.txt", aff_for, fmt="%1.5f")
	da, dw, db = affine_backwards(dZ, A, W)
	np.savetxt("affine_backward_da.txt", da, fmt="%1.5f")
	np.savetxt("affine_backward_dw.txt", dw, fmt="%1.5f")
	np.savetxt("affine_backward_db.txt", db, fmt="%1.5f")
	
if __name__ == "__main__":
	main()
